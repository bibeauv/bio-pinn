{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy.io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bio.csv', sep=',')\n",
    "data = data.replace(np.nan, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data['t'].to_numpy().reshape(-1,1)\n",
    "cB = data['cB'].to_numpy().reshape(-1,1)\n",
    "cTG = data['cTG'].to_numpy().reshape(-1,1)\n",
    "cDG = data['cDG'].to_numpy().reshape(-1,1)\n",
    "cMG = data['cMG'].to_numpy().reshape(-1,1)\n",
    "cG = data['cG'].to_numpy().reshape(-1,1)\n",
    "c = np.concatenate((cB, cTG, cDG, cMG, cG), axis=1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_points = 4\n",
    "\n",
    "t_train = np.linspace(t[0], t[-1], total_points)\n",
    "\n",
    "idx = []\n",
    "for ti in t:\n",
    "    idx.append(np.where(t_train.reshape(-1,1) == ti)[0][0])\n",
    "idx = np.array(idx)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train = np.zeros((total_points,5))\n",
    "c_train[idx,0] = cB.flatten()\n",
    "c_train[idx,1] = cTG.flatten()\n",
    "c_train[idx,2] = cDG.flatten()\n",
    "c_train[idx,3] = cMG.flatten()\n",
    "c_train[idx,-1] = cG.flatten()\n",
    "c_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = torch.from_numpy(t_train).float().to(device)\n",
    "c_train = torch.from_numpy(c_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = 1.\n",
    "k2 = 1.\n",
    "k3 = 1.\n",
    "k4 = 1.\n",
    "k5 = 1.\n",
    "k6 = 1.\n",
    "\n",
    "layers = np.array([1,10,10,10,5])\n",
    "\n",
    "f_hat = torch.zeros(t_train.shape[0],1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "     \n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "\n",
    "        for i in range(len(layers)-1):\n",
    "            \n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            \n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "    def forward(self, x):\n",
    "              \n",
    "        if torch.is_tensor(x) != True:\n",
    "            x = torch.from_numpy(x)\n",
    "        \n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            \n",
    "            z = self.linears[i](a)\n",
    "                        \n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a)\n",
    "        \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN():\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "        self.loss_function = nn.MSELoss(reduction = 'mean')\n",
    "\n",
    "        self.iter = 0\n",
    "\n",
    "        self.k1 = torch.tensor([k1], requires_grad=True).float().to(device)\n",
    "        self.k2 = torch.tensor([k2], requires_grad=True).float().to(device)\n",
    "        self.k3 = torch.tensor([k3], requires_grad=True).float().to(device)\n",
    "        self.k4 = torch.tensor([k4], requires_grad=True).float().to(device)\n",
    "        self.k5 = torch.tensor([k5], requires_grad=True).float().to(device)\n",
    "        self.k6 = torch.tensor([k6], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.k1 = nn.Parameter(self.k1)\n",
    "        self.k2 = nn.Parameter(self.k2)\n",
    "        self.k3 = nn.Parameter(self.k3)\n",
    "        self.k4 = nn.Parameter(self.k4)\n",
    "        self.k5 = nn.Parameter(self.k5)\n",
    "        self.k6 = nn.Parameter(self.k6)\n",
    "\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "        \n",
    "        self.dnn.register_parameter('k1', self.k1)\n",
    "        self.dnn.register_parameter('k2', self.k2)\n",
    "        self.dnn.register_parameter('k3', self.k3)\n",
    "        self.dnn.register_parameter('k4', self.k4)\n",
    "        self.dnn.register_parameter('k5', self.k5)\n",
    "        self.dnn.register_parameter('k6', self.k6)\n",
    "        \n",
    "    def loss_data(self, x, y):\n",
    "        \n",
    "        #cum_loss = []\n",
    "        #for i in range(5):\n",
    "        #    loss_c = self.loss_function(self.dnn(x)[:,i], y[:,i].reshape(-1,1))\n",
    "        #    if all(y[:,i] == 0):\n",
    "        #        loss_c.zero_()\n",
    "        #    cum_loss.append(loss_c)\n",
    "            \n",
    "        loss_u = self.loss_function(self.dnn(x), y)\n",
    "        \n",
    "        return loss_u\n",
    "    \n",
    "    def dc_dt(self, x, i):\n",
    "        \n",
    "        g = x.clone()\n",
    "        \n",
    "        g.requires_grad = True\n",
    "        \n",
    "        conc = self.dnn(g)\n",
    "        \n",
    "        grad_c = autograd.grad(conc[:,i].reshape(-1,1), g, torch.ones(x.shape[0], 1).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        return grad_c\n",
    "    \n",
    "    def c_t(self, x, i):\n",
    "        \n",
    "        conc = self.dnn(x)\n",
    "        \n",
    "        eval_c = conc[:,i].reshape(-1,1)\n",
    "        \n",
    "        return eval_c\n",
    "    \n",
    "    def loss_ode(self, x, y):\n",
    "                 \n",
    "        loss_f = self.loss_function(self.dc_dt(x, 1) + self.k1*self.c_t(x, 1) - self.k2*self.c_t(x, 2)*self.c_t(x, 0), f_hat) + \\\n",
    "                 self.loss_function(self.dc_dt(x, 2) - self.k1*self.c_t(x, 1) + self.k2*self.c_t(x, 2)*self.c_t(x, 0) \\\n",
    "                                                     + self.k3*self.c_t(x, 2) - self.k4*self.c_t(x, 3)*self.c_t(x, 0), f_hat) + \\\n",
    "                 self.loss_function(self.dc_dt(x, 3) - self.k3*self.c_t(x, 2) + self.k4*self.c_t(x, 3)*self.c_t(x, 0) \\\n",
    "                                                     + self.k5*self.c_t(x, 3) - self.k6*self.c_t(x, 4)*self.c_t(x, 0), f_hat) + \\\n",
    "                 self.loss_function(self.dc_dt(x, 4) - self.k5*self.c_t(x, 3) + self.k6*self.c_t(x, 4)*self.c_t(x, 0), f_hat) + \\\n",
    "                 self.loss_function(self.dc_dt(x, 0) - self.k1*self.c_t(x, 1) + self.k2*self.c_t(x, 2)*self.c_t(x, 0) \\\n",
    "                                                     - self.k3*self.c_t(x, 2) + self.k4*self.c_t(x, 3)*self.c_t(x, 0) \\\n",
    "                                                     - self.k5*self.c_t(x, 3) + self.k6*self.c_t(x, 4)*self.c_t(x, 0), f_hat)\n",
    "        \n",
    "        return loss_f\n",
    "    \n",
    "    def closure(self):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_u = self.loss_data(t_train, c_train)\n",
    "        loss_f = self.loss_ode(t_train, c_train)\n",
    "        \n",
    "        loss = 100*loss_u + loss_f\n",
    "        \n",
    "        (100*loss_u + loss_f).backward()\n",
    "                \n",
    "        self.iter += 1\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINN = FCN(layers)\n",
    "\n",
    "print(PINN.dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(PINN.dnn.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "while PINN.iter < 1000:\n",
    "    optimizer.step(PINN.closure)\n",
    "    for p in PINN.dnn.parameters():\n",
    "        p.data.clamp_(min=0)\n",
    "\n",
    "print(PINN.dnn(t_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PINN.loss_data(t_train, c_train))\n",
    "print(PINN.loss_ode(t_train, c_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDO(y, prm):\n",
    "    \n",
    "    k1 = prm[0]\n",
    "    k2 = prm[1]\n",
    "    k3 = prm[2]\n",
    "    k4 = prm[3]\n",
    "    k5 = prm[4]\n",
    "    k6 = prm[5]\n",
    "    \n",
    "    f = np.zeros(5)\n",
    "    \n",
    "    f[1] = - k1*y[1] + k2*y[2]*y[0]\n",
    "    f[2] = + k1*y[1] - k2*y[2]*y[0] - k3*y[2] + k4*y[3]*y[0]\n",
    "    f[3] = + k3*y[2] - k4*y[3]*y[0] - k5*y[3] + k6*y[4]*y[0]\n",
    "    f[4] = + k5*y[3] - k6*y[4]*y[0]\n",
    "    f[0] = + k1*y[1] - k2*y[2]*y[0] + k3*y[2] - k4*y[3]*y[0] + k5*y[3] - k6*y[4]*y[0]\n",
    "    \n",
    "    return f\n",
    "\n",
    "def euler_explicite(y0, dt, tf, prm):\n",
    "    \n",
    "    mat_y = np.array([y0])\n",
    "    \n",
    "    t = np.array([0])\n",
    "    while t[-1] < tf:\n",
    "        y = y0 + dt * EDO(y0, prm)\n",
    "        \n",
    "        mat_y = np.append(mat_y, [y], axis=0)\n",
    "        t = np.append(t, t[-1]+dt)\n",
    "        \n",
    "        y0 = np.copy(y)\n",
    "    \n",
    "    return t, mat_y\n",
    "\n",
    "prm = []        \n",
    "for i in range(6):\n",
    "    prm.append(params[:6][i][0].cpu().detach().numpy())\n",
    "    \n",
    "t_euler, y_euler = euler_explicite(np.array([0,0.540121748,0.057018273,0,0]), 0.001, 6, prm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_euler, y_euler[:,0])\n",
    "plt.plot(t_train.detach().numpy(), PINN.dnn(t_train).detach().numpy()[:,0])\n",
    "plt.plot(t, cB, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_euler, y_euler[:,1])\n",
    "plt.plot(t_train.detach().numpy(), PINN.dnn(t_train).detach().numpy()[:,1])\n",
    "plt.plot(t, cTG, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_euler, y_euler[:,2])\n",
    "plt.plot(t_train.detach().numpy(), PINN.dnn(t_train).detach().numpy()[:,2])\n",
    "plt.plot(t, cDG, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_euler, y_euler[:,3])\n",
    "plt.plot(t_train.detach().numpy(), PINN.dnn(t_train).detach().numpy()[:,3])\n",
    "plt.plot(t, cMG, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_euler, y_euler[:,4])\n",
    "plt.plot(t, cG, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f538c6a538005cf3b39e004aac3ceb405c590ed47051b2fc8a4226903742b65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
